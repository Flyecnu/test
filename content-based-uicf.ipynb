{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from nltk.stem.porter import*\n",
    "from nltk.text import TextCollection\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "src_path = 'C:/Users/JyoXu/RS/Assign-2-data/'\n",
    "train_path = src_path + 'train.csv'\n",
    "valid_path = src_path + 'valid.csv'\n",
    "test_path  = src_path + 'test.csv'\n",
    "\n",
    "dst_path = 'C:/Users/JyoXu/RS/Assign-2-result/'\n",
    "matrix_path = dst_path + 'matrix.csv'\n",
    "user_ave_path = dst_path + 'user_ave.csv'\n",
    "item_ave_path = dst_path + 'item_ave.csv'\n",
    "isim_path = dst_path + 'isim.csv'\n",
    "usim_path = dst_path + 'usim.csv'\n",
    "csim_path = dst_path + 'csim.csv'\n",
    "pca_path  = dst_path + 'tf_idf_pca.csv'\n",
    "item_review_path = dst_path + 'item_review.csv'\n",
    "ineighbor_path = dst_path + 'ineighbor.csv'\n",
    "uneighbor_path = dst_path + 'uneighbor.csv'\n",
    "cneighbor_path = dst_path + 'cneighbor.csv'\n",
    "valid_res_path = dst_path + 'valid_res.csv'\n",
    "review_path = dst_path + 'review.csv'\n",
    "\n",
    "sub_path = 'C:/Users/JyoXu/RS/Assign-2-submission/'\n",
    "saved_path  = sub_path + 'res_a%.1f b%.1f c%.1f d%.1f.csv'\n",
    "################################\n",
    "\n",
    "class CF:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def dump(self, src, to_path):\n",
    "        writer = csv.writer(open(to_path,'w',newline=''))\n",
    "        for i in range (np.shape(src)[0]):\n",
    "            writer.writerow(src[i])\n",
    "        return\n",
    "\n",
    "    def split_valid_data(self, path, to_path, rate, round):\n",
    "        f = csv.reader(open(path,'r'))  # 源\n",
    "        writer = csv.writer(open(to_path, 'w', newline='')) # 写入验证集\n",
    "        start = int(9029 * rate * round)       # valid data 起点\n",
    "        total = int(9029 * rate)\n",
    "        idx, cnt = 0, 0\n",
    "        for i in f:\n",
    "            if i[0] == 'reviewerID':\n",
    "                writer.writerow(i)\n",
    "                continue\n",
    "            if ( idx < start ):\n",
    "                idx += 1\n",
    "                continue\n",
    "            # 当前条目的用户编号和商品编号\n",
    "            unum, inum = self.user_dict[i[0]], self.item_dict[i[1]]\n",
    "            # 保证有足够的训练集\n",
    "            if ( self.user_active[unum] >= 5 and self.item_active[inum] >= 5 ):\n",
    "                # 写入验证集\n",
    "                writer.writerow(i)\n",
    "                # 从训练集中去除\n",
    "                self.user_active[unum] -= 1\n",
    "                self.item_active[inum] -= 1\n",
    "                self.users_per_item[inum].remove(unum) # item[i] 对应的诸多user\n",
    "                self.items_per_user[unum].remove(inum)\n",
    "                self.matrix[unum][inum] = 0\n",
    "                self.pos[unum][inum] = -1\n",
    "                cnt += 1\n",
    "            if ( cnt == total ): # 收集满total条验证集\n",
    "                break\n",
    "        self.dump(self.matrix, matrix_path) # 输出 ui_matrix\n",
    "        return self\n",
    "\n",
    "    def load_train_data(self, path):\n",
    "        self.user_dict, self.item_dict = {}, {}\n",
    "        self.users_per_item = defaultdict(set)\n",
    "        self.items_per_user = defaultdict(set)\n",
    "        i, j = 0, 0\n",
    "        reader = csv.reader(open(path,'r'))\n",
    "        for k in reader: # 编号\n",
    "            if k[0] == 'reviewerID':\n",
    "                continue\n",
    "            uid, iid = k[0], k[1]\n",
    "            if uid not in self.user_dict:\n",
    "                self.user_dict[uid]=i\n",
    "                i+=1\n",
    "            if iid not in self.item_dict:\n",
    "                self.item_dict[iid]=j\n",
    "                j+=1\n",
    "        self.reviewText = []  # 新增了reviewText，用一个list来存储\n",
    "        self.matrix = np.zeros((len(self.user_dict),len(self.item_dict)))\n",
    "        self.pos    = np.full((len(self.user_dict),len(self.item_dict)),-1)\n",
    "        \n",
    "        # 用户、商品活跃度（相关评分数量）\n",
    "        self.user_active = np.zeros(len(self.user_dict))\n",
    "        self.item_active = np.zeros(len(self.item_dict))\n",
    "        # \n",
    "        reader = csv.reader(open(path,'r'))\n",
    "        for line in reader:\n",
    "            if line[0] == 'reviewerID':\n",
    "                continue\n",
    "            u, i = self.user_dict[line[0]], self.item_dict[line[1]]\n",
    "            self.matrix[u][i] = eval(line[2])\n",
    "            self.users_per_item[i].add(u) # item[i] 对应的诸多user\n",
    "            self.items_per_user[u].add(i)\n",
    "            self.pos[u][i] = len(self.reviewText)\n",
    "            self.reviewText.append(line[3])  # 添加review\n",
    "            #\n",
    "            self.user_active[self.user_dict[line[0]]] += 1 # 更新用户活跃度\n",
    "            self.item_active[self.item_dict[line[1]]] += 1 # 更新商品活跃度\n",
    "        self.matrix=self.matrix.astype(np.float32)\n",
    "        self.dump(self.matrix, matrix_path) # 输出 ui_matrix\n",
    "        return self\n",
    "\n",
    "    def init(self):\n",
    "        self.able = 0\n",
    "        self.usim = np.zeros((len(self.user_dict), len(self.user_dict)))\n",
    "        self.isim = np.zeros((len(self.item_dict), len(self.item_dict)))\n",
    "        self.csim = np.zeros((len(self.item_dict), len(self.item_dict)))\n",
    "        self.uneighbor = np.zeros((len(self.user_dict), len(self.user_dict)))\n",
    "        self.ineighbor = np.zeros((len(self.item_dict), len(self.item_dict)))\n",
    "        self.cneighbor = np.zeros((len(self.item_dict), len(self.item_dict)))\n",
    "        return self\n",
    "    \n",
    "    def user_ave_cal(self, to_path):\n",
    "        # 计算每个用户的平均给分\n",
    "        self.user_ave_score = np.sum(self.matrix,axis=1) / self.user_active\n",
    "        self.user_ave_score = np.reshape(self.user_ave_score,(len(self.user_ave_score),1))\n",
    "        self.all_user_ave = np.sum(self.user_ave_score) / len(self.user_ave_score)\n",
    "        print(\"all_user_ave %.5f\"%self.all_user_ave)\n",
    "        self.dump(self.user_ave_score, to_path) # 导出\n",
    "        return self\n",
    "\n",
    "    def item_ave_cal(self, to_path):\n",
    "        # 计算每个商品的平均得分\n",
    "        self.item_ave_score = np.sum(self.matrix,axis=0) / self.item_active\n",
    "        self.item_ave_score = np.reshape(self.item_ave_score,(len(self.item_ave_score),1))\n",
    "        self.all_item_ave = np.sum(self.item_ave_score) / len(self.item_ave_score)\n",
    "        print(\"all_item_ave %.5f\"%self.all_item_ave)\n",
    "        self.dump(self.item_ave_score, to_path) # 导出\n",
    "        return self\n",
    "    \n",
    "    def load_sim(self, dst, path):\n",
    "        reader = csv.reader(open(path,'r'))  # 源\n",
    "        i = 0\n",
    "        for line in reader: # 每一行 sim[a]\n",
    "            j = 0\n",
    "            for e in line:  # 每一个元素，sim[a][b]\n",
    "                dst[i][j] = e\n",
    "                j += 1\n",
    "            i += 1\n",
    "        return self\n",
    "    \n",
    "    def cos_sim_cal(self, src, dst, to_path, act, cons=[]):\n",
    "        for i in range(len(src)):\n",
    "            if ( i % 200 == 0 ):\n",
    "                print(i)\n",
    "            for j in range(len(src)):\n",
    "                if ( len(cons) != 0 ):\n",
    "                    # 共同交互少于4，或活跃度太低不考虑相似度\n",
    "                    if ( len(cons[i].intersection(cons[j]))<4 or act[i]<5 or act[j]<5):\n",
    "                        dst[i][j] = 0\n",
    "                        continue\n",
    "                v1 = src[i] # 向量1\n",
    "                v2 = src[j] # 向量2\n",
    "                num = float(np.dot(v1, v2)) # 点乘\n",
    "                denom = np.linalg.norm(v1) * np.linalg.norm(v2) # 取模\n",
    "                dst[i][j] = (num / denom) if denom != 0 else 0\n",
    "        self.dump(dst, to_path)\n",
    "        return\n",
    "        \n",
    "    def clean_text(self):\n",
    "        # 引入标点符号\n",
    "        punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "        # 转换为小写，去除标点符号\n",
    "        for i in range(len(self.reviewText)):\n",
    "            self.reviewText[i] = self.reviewText[i].lower().translate(punctuation_map)\n",
    "        # 对每个句子进行分词\n",
    "        self.reviewText = [word_tokenize(re) for re in self.reviewText]\n",
    "        # 去除停用词\n",
    "        for i in range(len(self.reviewText)):\n",
    "            if ( i % 100 == 0 ):\n",
    "                print(\"stop word %d\"%i)\n",
    "            self.reviewText[i] = [w for w in self.reviewText[i] if not w in stopwords.words('english')]\n",
    "        # 提取词干\n",
    "        s = nltk.stem.SnowballStemmer('english')\n",
    "        for i in range(len(self.reviewText)):\n",
    "            for j in range(len(self.reviewText[i])):\n",
    "                self.reviewText[i][j] = s.stem(self.reviewText[i][j])\n",
    "        print(\"clean text done\")\n",
    "        # 拼接\n",
    "        self.text = [' '.join(i) for i in self.reviewText]\n",
    "        self.reviewText = []\n",
    "        for i in range(len(self.item_dict)): # 对每个item收集它的评论\n",
    "            self.reviewText.append('')\n",
    "        for u in range(len(self.user_dict)):\n",
    "            for i in range(len(self.item_dict)):\n",
    "                p = int(self.pos[u][i])\n",
    "                if ( p != -1 ):\n",
    "                    self.reviewText[i] += self.text[p]\n",
    "        #print(self.reviewText)\n",
    "        return self\n",
    "    \n",
    "    def tf_idf(self):\n",
    "        self.clean_text()\n",
    "        #该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "        vectorizer = CountVectorizer()\n",
    "        #该类会统计每个词语的tf-idf权值\n",
    "        tf_idf_transformer = TfidfTransformer()\n",
    "        #将文本转为词频矩阵并计算tf-idf\n",
    "        tf_idf = tf_idf_transformer.fit_transform(vectorizer.fit_transform(self.reviewText))\n",
    "        #将tf-idf矩阵抽取出来，元素a[i][j]表示j词在i类文本中的tf-idf权重\n",
    "        self.tf_idf_matrix = tf_idf.toarray()\n",
    "        print(\"tf-idf done\")\n",
    "        print(self.tf_idf_matrix)\n",
    "        print(np.shape(self.tf_idf_matrix))\n",
    "        return\n",
    "    \n",
    "    def pca(self, ndim = 2000):\n",
    "        pca = PCA(n_components=ndim)\n",
    "        # reduce the dimension of feature vectors\n",
    "        self.tf_idf_pca = pca.fit_transform(self.tf_idf_matrix)\n",
    "        # save the reduced tf-idf matrix\n",
    "        self.dump(self.tf_idf_pca, pca_path)\n",
    "        return\n",
    "    \n",
    "    def sim_cal(self, loadcsim=1, load=1):\n",
    "        if ( load ):\n",
    "            self.load_sim(self.usim, usim_path)\n",
    "            self.load_sim(self.isim, isim_path)\n",
    "        else:\n",
    "            self.cos_sim_cal(self.matrix, self.usim, usim_path, self.user_active, self.items_per_user)\n",
    "            self.cos_sim_cal(np.transpose(self.matrix), self.isim, isim_path, self.item_active, self.users_per_item)\n",
    "            \n",
    "        if ( loadcsim ):\n",
    "            self.load_sim(self.csim, csim_path)\n",
    "        else:\n",
    "            self.tf_idf()\n",
    "            # pca ############\n",
    "            self.pca(2000)\n",
    "            print(\"pca done\")\n",
    "            # 计算相似度\n",
    "            self.cos_sim_cal(self.tf_idf_pca, self.csim, csim_path)\n",
    "        # 相似度排序\n",
    "        self.neighbor_sort(self.usim, self.uneighbor, uneighbor_path)\n",
    "        self.neighbor_sort(self.isim, self.ineighbor, ineighbor_path)\n",
    "        self.neighbor_sort(self.csim, self.cneighbor, cneighbor_path)\n",
    "        return self\n",
    "    \n",
    "    # 按相似度从高到低为邻居排序\n",
    "    def neighbor_sort(self, src, dst, to_path):\n",
    "        for i in range (len(dst)):\n",
    "            dst[i] = src[i].argsort()[::-1]\n",
    "        self.dump(dst, to_path)\n",
    "        return self\n",
    "    \n",
    "    def predict_1rating(self, unum, inum):\n",
    "        '''\n",
    "        根据共现矩阵，计算一次rating\n",
    "        '''\n",
    "        utotal, uweigh, itotal, iweigh, pred_ui = 0, 0, 0, 0, 0\n",
    "        usim, isim = [], []\n",
    "        # ucf ###########\n",
    "        cnt = 0\n",
    "        for u in range(len(self.user_dict)):    # 遍历用户邻居表\n",
    "            user = int(self.uneighbor[unum][u]) # 当前考察的邻居\n",
    "            if ( user == unum ):                # 跳过自己\n",
    "                continue\n",
    "            # 调整阈值 ##############################################\n",
    "            if ( self.usim[user][unum] <= 0.2 or cnt == 5 ): # 相似用户\n",
    "                break\n",
    "            #########################################################\n",
    "            r_ui = self.matrix[user][inum]      # 用户邻居user对inum的打分\n",
    "            if ( r_ui > 0 ):                    # 打过分\n",
    "                r_u = self.user_ave_score[user] # 该邻居打分均值\n",
    "                utotal += self.usim[unum][user] * ( r_ui - r_u )\n",
    "                uweigh += self.usim[unum][user]\n",
    "                usim.append(self.usim[unum][user])\n",
    "                cnt += 1\n",
    "        if ( abs(uweigh) < 1e-10 ): # 没有相似用户评价过inum\n",
    "            ucfpred = self.theta*(self.gama*self.user_ave_score[unum]+(1-self.gama)*self.item_ave_score[inum])+(1-self.theta)*self.all_user_ave\n",
    "        else:\n",
    "            ucfpred = self.user_ave_score[unum] + utotal / uweigh\n",
    "        if ( ucfpred < 1 ):\n",
    "            ucfpred = 1\n",
    "        elif ( ucfpred > 5 ):\n",
    "            ucfpred = 5\n",
    "        # icf ###########\n",
    "        cnt = 0\n",
    "        for i in range(len(self.item_dict)):    # 遍历物品邻居表\n",
    "            item = int(self.ineighbor[inum][i]) # 当前考察的邻居\n",
    "            if ( item == inum ):                # 跳过自己\n",
    "                continue\n",
    "            # 调整阈值 ##############################################\n",
    "            if ( self.isim[item][inum] <= 0.2 or cnt == 5 ): # 相似物品\n",
    "                break\n",
    "            #########################################################\n",
    "            r_ui = self.matrix[unum][item]      # u对inum的邻居item的打分\n",
    "            if ( r_ui > 0 ):                    # 打过分\n",
    "                itotal += self.isim[item][inum] * r_ui\n",
    "                iweigh += self.isim[item][inum]\n",
    "                isim.append(self.isim[item][inum])\n",
    "                cnt += 1\n",
    "        if ( abs(iweigh) < 1e-10 ): # unum没有交互过相似物品\n",
    "            icfpred = self.theta*(self.gama*self.user_ave_score[unum]+(1-self.gama)*self.item_ave_score[inum])+(1-self.theta)*self.all_item_ave\n",
    "        else:\n",
    "            icfpred = self.item_ave_score[inum] + itotal / iweigh\n",
    "        if ( icfpred < 1 ):\n",
    "            icfpred = 1\n",
    "        elif ( icfpred > 5 ):\n",
    "            icfpred = 5\n",
    "        # content-based ###########\n",
    "        for i in range(len(self.item_dict)):    # 遍历物品邻居表\n",
    "            item = int(self.cneighbor[inum][i]) # 当前考察的邻居\n",
    "            if ( item == inum ):                # 跳过自己\n",
    "                continue\n",
    "            # 调整阈值 ##############################################\n",
    "            if ( self.csim[item][inum] <= 0.2 ): # 相似物品\n",
    "                break\n",
    "            #########################################################\n",
    "            r_ui = self.matrix[unum][item]      # u对inum的邻居item的打分\n",
    "            if ( r_ui > 0 ):                    # 打过分\n",
    "                itotal += self.csim[item][inum] * r_ui\n",
    "                iweigh += self.csim[item][inum]\n",
    "                isim.append(self.csim[item][inum])\n",
    "        if ( abs(iweigh) < 1e-10 ): # unum没有交互过相似物品\n",
    "            cbpred = self.all_user_ave\n",
    "        else:\n",
    "            cbpred = itotal / iweigh\n",
    "        if ( cbpred < 1 ):\n",
    "            cbpred = 1\n",
    "        elif ( cbpred > 5 ):\n",
    "            cbpred = 5\n",
    "        # 综合 ######################\n",
    "        pred_ui = self.beta * ( self.alpha * ucfpred + ( 1 - self.alpha ) * icfpred ) + ( 1 - self.beta ) * cbpred\n",
    "        #print(unum, inum, usim, isim, pred_ui)\n",
    "        self.able += 1\n",
    "\n",
    "        # bounding\n",
    "        if ( pred_ui < 1 ):\n",
    "            pred_ui = self.all_user_ave\n",
    "        if ( pred_ui > 5 ):\n",
    "            pred_ui = 5\n",
    "        return np.squeeze(pred_ui)\n",
    "\n",
    "    def predict_RMSE(self, path, to_path):\n",
    "        '''\n",
    "        提供一个计算RMSE的方法\n",
    "        '''\n",
    "        predicted_list=[]\n",
    "        gt_rate_list=[]\n",
    "        #1.read valid data & compute scores\n",
    "        f = csv.reader(open(path,'r'))\n",
    "        self.able = 0\n",
    "        self.accurate = 0\n",
    "        for i in f:\n",
    "            if i[0] == 'reviewerID':\n",
    "                continue\n",
    "            unum,inum,gt_rate = self.user_dict[i[0]],self.item_dict[i[1]],eval(i[2])\n",
    "            predicted_score = self.predict_1rating(unum, inum)\n",
    "            predicted_list.append(predicted_score)\n",
    "            gt_rate_list.append(gt_rate)\n",
    "            if ( predicted_score == gt_rate ):\n",
    "                self.accurate += 1\n",
    "        RMSE = 0.0\n",
    "        #2.compute RMSE\n",
    "        data_len=len(predicted_list)\n",
    "        RMSE=sum([((predicted_list[i]-gt_rate_list[i])**2) / data_len for i in range(data_len)]) ** 0.5\n",
    "        print('RMSE',RMSE)\n",
    "        print('able',self.able)\n",
    "        print('accurate',self.accurate)\n",
    "        \n",
    "        # 输出验证集测试结果\n",
    "        writer = csv.writer(open(valid_res_path,'w', newline=''))\n",
    "        for i in range(len(predicted_list)):\n",
    "            writer.writerow([gt_rate_list[i], predicted_list[i]])\n",
    "        \n",
    "        # 可视化预测结果\n",
    "        plt.style.use('ggplot')\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.scatter([i for i in range(len(predicted_list))], gt_rate_list, alpha=0.7, label='rate')\n",
    "        plt.scatter([i for i in range(len(predicted_list))], predicted_list, alpha=0.7, label='predicted rate')\n",
    "        plt.legend(loc=[1, 1], fontsize=10)\n",
    "        plt.title('Prediction results on the validation set (RMSE: %.5f)'%RMSE)\n",
    "        plt.xlabel('index')\n",
    "        plt.ylabel('score')\n",
    "        return RMSE\n",
    "    \n",
    "    def save_pred(self, path, to_path):\n",
    "        f = csv.reader(open(path,'r'))\n",
    "        writer = csv.writer(open(to_path,'w', newline=''))\n",
    "        writer.writerow(['idx','overall'])\n",
    "        cnt = 0\n",
    "        self.able = 0\n",
    "        for i in f:\n",
    "            if i[0] == 'reviewerID':\n",
    "                continue\n",
    "            unum,inum = self.user_dict[i[0]],self.item_dict[i[1]]\n",
    "            predicted_score = self.predict_1rating(unum, inum)\n",
    "            writer.writerow([cnt,predicted_score])\n",
    "            cnt += 1\n",
    "        print('able',self.able)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集/验证集\n",
    "model=CF()\n",
    "model.load_train_data(train_path)\n",
    "#model.split_valid_data(train_path, valid_path, 0.1, 1)\n",
    "model.init()\n",
    "\n",
    "model.user_ave_cal(user_ave_path)\n",
    "model.item_ave_cal(item_ave_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadcsim: 是否导入文本相似度\n",
    "# load: 是否导入 user sim & item sim\n",
    "model.sim_cal(loadcsim=1,load=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据验证集调参结果修改\n",
    "model.alpha, model.beta, model.gama, model.theta = 0.5, 0.9, 0.5, 0.7\n",
    "# 保存预测结果\n",
    "model.save_pred(test_path,saved_path%(model.alpha,model.beta,model.gama,model.theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出预测结果\n",
    "sub_path = 'C:/Users/JyoXu/RS/Assign-2-submission/'\n",
    "\n",
    "score = ['res_a%.1f b%.1f c%.1f d%.1f'%(model.alpha,model.beta,model.gama,model.theta)]\n",
    "\n",
    "# 可视化预测结果\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15, 4))\n",
    "for s in range(len(score)):\n",
    "    f = csv.reader(open(sub_path+score[s]+'.csv','r'))  # 源\n",
    "    idx = np.zeros(1232)\n",
    "    pre = np.zeros(1232)\n",
    "    cnt = 0\n",
    "    for k in f:\n",
    "        if k[0] == 'idx':\n",
    "            continue\n",
    "        idx[cnt] = eval(k[0])\n",
    "        pre[cnt] = eval(k[1])\n",
    "        cnt += 1\n",
    "    plt.scatter(idx, pre, alpha=0.8, label=score[s])\n",
    "\n",
    "plt.legend(loc=[1, 1], fontsize=10)\n",
    "plt.title('Prediction results')\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('score')\n",
    "plt.yticks((1,1.5,2,2.5,3,3.5,4,4.5,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
